---
title: Projeto de BI na pr√°tica
updated: 2024-08-08 13:45:35Z
created: 2024-05-27 20:23:08Z
latitude: -23.52396230
longitude: -46.84112430
altitude: 0.0000
---

[toc]

# Carga Staging

Momento em que passamos os dados da base OLTP para o Staging OLAP. Depois, faremos a divis√£o e carga de nossas tabelas em Fato e Dimens√£o. N√≥s fizemos a carga no OLAP apenas das bases que queriamos do OLTP. Agora dividiremos em Dimens√£o e Fato.

## Cria√ß√£o das conex√µes OLTP e OLAP

Para isso, usando o talend, criamos uma conex√£o com nossa base OLTP e outra para nosso OLAP (Origem - Destino), para isso, ir em "metadata" e "DB Connection". Bot√£o direito e ai "criar conex√£o". Seguir o Wizard. Ao final, colocar o login e senha da base OLTP do SQL Server (conex√£o somente de leitura). Exemplo de conex√£o:  
![f838c29f4901fdfe0209adea041a29ec.png](../_resources/f838c29f4901fdfe0209adea041a29ec.png)

Seguir os mesmos passos para a conex√£o da base OLAP por√©m muda o login, senha e instancia. Exemplo conex√£o OLAP:  
![58e811215aeee69a972e25034568e679.png](../_resources/58e811215aeee69a972e25034568e679.png)

Geralmente em ambientes profissionais, as bases OLAP e OLTP est√£o em servidores diferentes para uma melhor performance, com isso n√£o precisariamos do par√¢metro "INSTANCE=OLAP", por√©m aqui fizemos as duas instancias no mesmo servidor, por isso precisamos desse parametro adicional.

Com as conex√µes criadas, podemos clicar na base OLTP e clicar em "retrieve schema", dar next e selecionar todas as tabelas que queremos, depois damos next novamente, com isso temos a estrutura de nosso banco de dados OLTP.

## Job de Carga de dados

Clicar com bot√£o direito em "Job Designs" e criar uma pasta chamada "Staging", para todos os jobs relacionados ao Staging. Clicar na pasta com bot√£o direito e ai sim criar o job. Apenas colocar o nome e descri√ß√£o. Com isso, ser√° aberta a pagina de design do job.  
<br/>Temos que colocar uma atividade de input chamada "t_DBInput" a qual recebe nossos dados de input, iremos para a configura√ß√£o dessa atividade, clicar em "componente" e selecionar um DB.¬†  
![bfe2c150ba0e09b8fa4ac8a7e5f1553c.png](../_resources/bfe2c150ba0e09b8fa4ac8a7e5f1553c.png)  
Em property type, escolher reposit√≥rio. Clicar no campo em branco que aparecer√° e depois escolher a base de dados OLTP (conex√£o que j√° criamos). Feito isso, precisamos de um schema, tamb√©m escolheremos reposit√≥rio, clicar nos "..." e escolher a tabela desejada, depois clicar em "guess query", ao final a configura√ß√£o deve ser algo assim:  
![cdff191239c31896b49bc63925cc6ae1.png](../_resources/cdff191239c31896b49bc63925cc6ae1.png)  
<br/>

A pr√≥xima atividade se chama "tMap" que faz o mapeamento, ligaremos a entrada de dados "t_input" com o mapeamento "t_map", para isso, clicar na atividade, clicar com bot√£o direito, selecionar "row" depois "main" e conectar com a outra atividade.

Feito isso, precisaremos de uma saida, sendo ela a "tDBOutput" e informaremos a esse elemento onde nossos dados ir√£o sair. Clique no elemento e depois em componente, igual fizemos com o input. Escolher o database, no meu caso o SQL Server e a base OLAP (configura√ß√£o do property type) de nosso reposit√≥rio de conex√µes que criamos no primeiro momento. No campo "tabela", colocar o nome da tabela de sa√≠da entre aspas, abaixo em "Action on table" selecionar "Create Table if not exists" e a√ß√£o do dado ser√° "inserir". Feito isso, o pr√≥ximo passo √© ligar o tMap ao tDBOutput, ser√° do mesmo jeito que fizemos antes. Ao final o output deve ser parecido com esse:  
![d94c3cf481257e9732160dd6fea86b43.png](../_resources/d94c3cf481257e9732160dd6fea86b43.png)  
Agora precisamos fazer o mapeamento, duplo clique em tMap:  
![23a31d1003d431b2c319627697ca6bb1.png](../_resources/23a31d1003d431b2c319627697ca6bb1.png)  
Acima vemos a entrada e sa√≠da de dados, ent√£o temos as colunas de entrada por√©m n√£o temos colunas de sa√≠da. Ent√£o com CTRL clique em todos os campos da tabela de entrada e arraste at√© a tabela de sa√≠da. Ficando algo assim:  
![fc20516c86449ba6a6d0f9787ab827d9.png](../_resources/fc20516c86449ba6a6d0f9787ab827d9.png)  
Depois, s√≥ clicar em ok e yes. Feito isso, l√° em nosso output foi liberado o bot√£o "sync columns", ao clicar nele nosso job estar√° pronto.  
<br/>Ao final, o job deve ser algo assim:  
![e7bff21df53e312bce5f3942e695f9e7.png](../_resources/e7bff21df53e312bce5f3942e695f9e7.png)  
<br/>Clique em Run, nessa aba de cofigura√ß√µes temos o parametro line limit, ent√£o por exemplo, a cada 100 linhas, ele grava a informa√ß√£o e faz o commit, isso serve para liberar mem√≥ria em disco, ent√£o digamos que temos uma tabela de 1 milh√£o de linhas, ent√£o a cada 1000 linhas poderiamos fazer um commit e come√ßa a gravar de novo, se deixarmos um valor muito alto pode causar um overflow e travamentos acontecer√£o, o processo ficar√° mais lento. Em meu caso, selecionarei o line limit e colocarei em 1000. E por fim, clique em rodar.

Para campos incrementais (ex: ID), no schema OLAP (output) o campo deve ser configurado apenas como INT e n√£o como INT Incremental, pois o incremento ja vem do OLTP. Nenhum incremento em Data Warehouses! N√£o mudamos nada do OLTP para OLAP, apenas lemos. (OLTP apenas leitura e OLAP todas as permiss√µes, isso √© feito na cria√ß√£o dos usu√°rios no SQL Server).

# Divis√£o do OLAP em Dimens√£o e Fato

Agora ser√° feita a divis√£o de nosso OLAP em dimens√£o e fato, dimens√£o √© o mais complicado de se fazer, pois teremos v√°rios joins de varias tabelas usando as chaves artificiais para criar apenas 1 tabela de dimens√£o, deve ser feito com aten√ß√£o e devemos entender bem de nossos dados antes de fazer isso.

## Cria√ß√£o das tabelas de Dimens√£o

Devem ser criadas as tabelas de dimens√£o de acordo com as regras de neg√≥cio, √© simples, apenas criamos tabelas vazias com os campos que queremos de cada tabela, por exemplo:  
![c946b99c0aded5df1001a856a24c363f.png](../_resources/c946b99c0aded5df1001a856a24c363f.png)

Criamos uma tabela vazia chamada "DIM_SUB_CATEGORIA" com os campos especificados acima e as chaves artificiais, as quais o talend lidar√£o.

## Carga de dados do Staging para Dimens√£o

Agora que ja temos nossas tabelas de dimens√£o criadas com as chaves artificiais e nossos dados dentro do Staging no OLAP, iremos carregar os dados do Staging para as tabelas de dimens√£o usando o SCD e as chaves artificiais.

Para isso, em Job Design no Talend criaremos uma outra pasta chamada "DIM". N√£o se esque√ßa de fazer um retrieve schema na conex√£o OLAP para as tabelas de dimens√£o aparecerem.

Para fazer o Job com uma chave artificial precisamos escolher a atividade "tDBSC" para tratarmos da chave estrangeira com o SCD do talend. Ao configurar o tMap, n√≥s n√£o alimentamos a chave artificial, ficando assim: ![e40c902603b78a247d3c40b1ed46b603.png](../_resources/e40c902603b78a247d3c40b1ed46b603.png)

A chave artificial "SK" ser√° alimentada pelo componente SCD.

Clicamos no componente de output tDBSC que criamos, clicamos em componente e depois em SCD editor. Nesse projeto utilizaremos o SCD tipo 1. Devemos pegar todos os campos do lado esquerdo (menos a chave artificial) e no meu caso o codigo da empresa (chave prim√°ria de nossa tabela) deve ficar em source keys e jogar no tipo 1.

Em Surrogate Keys (chave artificial) devemos escrever o nome da nossa chave artificial, no meu caso √© "SK_EMPRESA". Em creation seleciono Table Max + 1 ou seja, sempre pegue o ultimo registro da tabela + 1. Source Key √© o campo em que ir√° ser criada a chave encima. E no final, deve ser algo assim:![085901e94e2a23e7e4ab92bac67886d9.png](../_resources/085901e94e2a23e7e4ab92bac67886d9.png)

Um outro exemplo de SCD:

![6b417aa3ba93bb95960fd9159e73dc77.png](../_resources/6b417aa3ba93bb95960fd9159e73dc77.png)

Podemos fazer filtros no tMap para levar apenas os dados que queremos, por exemplo:  
![c3286035238e20b8213c013621822f49.png](../_resources/c3286035238e20b8213c013621822f49.png)  
Aqui, levaremos apenas os dados em que o c√≥digo de cargo √© 2 ou 3.

## Ler dados de duas tabelas e ter output de 1 tabela

Para fazer um join entre tabelas e usar duas tabelas para ter o output de 1, no talend usamos a atividade "tAggregateRow". Ent√£o, usaremos as 2 tabelas de input, 1 tMap, 1 tAggregateRow e 1 saida (tabela que queremos que nossos dados fiquem, nesse caso, a DIM_GERENTES) do tipo tDBSCD. O tAggregateRow deve ter o mesmo schema da tabela de saida. Ainda na configura√ß√£o do tAggregateRow, ligamos essa atividade com a atividade de sa√≠da, vamos na configura√ß√£o de componenente do Aggregate e em "grupo por" adicionamos todos os campos, clicando no "+":  
![7557fa7fd57a1529e50b1e03d3585f33.png](../_resources/7557fa7fd57a1529e50b1e03d3585f33.png)  
A configura√ß√£o do tAggregateRow deve ser como essa acima.

Uma das partes mais importantes dessa agrega√ß√£o √© linkar as tabelas no tMap. Temos que linkar todas as chaves primarias das 2 tabelas que queremos fazer o "join", depois clicamos em "tMap Settings" > "Match Model" > "Todas as Combina√ß√µes" > "Ok" e na op√ß√£o "Join Model" usaremos o inner join (ou outro que julgue necess√°rio). Deve ficar assim:  
![c53c12f96664a29b742b47f591019513.png](../_resources/c53c12f96664a29b742b47f591019513.png)

Agora ligamos o tMap ao Aggregate, clicamos novamente no tMap e ligaremos os campos das tabelas com o da sa√≠da. Ficando dessa maneira:  
![95b65a12e9e7bf88eab53a2c7afd1d07.png](../_resources/95b65a12e9e7bf88eab53a2c7afd1d07.png)

Por ultimo, configuraremos o SCD:  
![2577f302f95a9059290bf7f5c5b55897.png](../_resources/2577f302f95a9059290bf7f5c5b55897.png)

E o tAggregateRow ao final deve ser esse:  
![7506e7977ffcd0e808b05aae0c7347cd.png](../_resources/7506e7977ffcd0e808b05aae0c7347cd.png)

Truncate elimina dados e os espa√ßos alocados, melhor que delete. Delete mant√©m espa√ßo alocado, truncate √© mais performatico. Por√©m delete tem Where.

O job geral das tabelas dimens√£o ou fato devem seguir a sequencia correta de cria√ß√£o inicial das tabelas.

# Organiza√ß√£o e Relacionamento de tabelas no PowerBI

Nossa tabela fato deve ficar ao centro, ela √© nossa principal tabela, em meu caso, √© a Fato_Venda. As outras tabelas de dimens√µes devem ficar ao redor da fato principal mas organizadas por assunto. Ent√£o por exemplo, eu tenho a tabela dim_material, logo todas as outras tabelas que tem algo envolvido com material, ficar√£o perto dela, pois a dim_material √© a principal tabela de materiais. Isso seria um modelo SnowFlake.![249680a96a6d694e0707af33132a6faa.png](../_resources/249680a96a6d694e0707af33132a6faa.png)  
Ficando mais ou menos como acima.

Agora podemos fazer os relacionamentos come√ßando de nossa tabela fato principal. No meu caso come√ßarei com a fato_venda com a tabela de empresa. Sempre come√ßar dos campos mais importantes aos menos importantes. Por isso as chaves artificiais criadas no momento de ETL s√£o importantes, usamos elas para fazer os relacionamentos das tabelas do PBI. N√≥s pegamos a tabela Fato principal e linkamos com as tabelas chave de dimens√£o, ou seja, as tabelas de dimens√£o que se relacionam com as outras dimens√µes.

Rela√ß√µes das principais dimens√µes com o fato principal:![4057d00d0d7f18e5acbbf7eaee1d2937.png](../_resources/4057d00d0d7f18e5acbbf7eaee1d2937.png)

Agora, s√≥ ligar as dimens√µes principais com as dimens√µes secund√°rias. E aqui ainda usamos as chaves artificiais. Aqui eu relacionei a dimens√£o material com suas dimens√µes secund√°rias:  
![15e21258b66b9de76a1d4fe59cc42faf.png](../_resources/15e21258b66b9de76a1d4fe59cc42faf.png)

Feito isso, temos o relacionamento pronto:  
![375cd68897d998f3db2a11b8d3451268.png](../_resources/375cd68897d998f3db2a11b8d3451268.png)

Vemos que n√£o temos nenhuma tabela flutuando, sem conex√£o com uma tabela fato com alguma dimens√£o ou fazendo o snowflake igual feito com a dim_material.

## Qual a melhor forma de validar nossos relacionamentos?

Como saber se nossos relacionamentos est√£o funcionando da maneira correta? A melhor forma √© abrindo uma p√°gina de rascunho no PBI, colocar uma tabela e nela colocar algumas informa√ß√µes importantes de forma a testar o relacionamento das tabelas dimens√£o com a fato. Em meu caso farei uma hierarquia de informa√ß√µes de vendas, ou seja, come√ßaremos com o nome da empresa (se √© matriz ou filial) e vamos fazendo o drill-down com os nomes dos gerentes das empresas, depois os nomes dos funcion√°rios alocados a cada gerente, e por ultimo, trarei da fato venda o valor unit√°rio:

![c7b888a78d999ef17b33768afbd82a72.png](../_resources/c7b888a78d999ef17b33768afbd82a72.png)

Nos podemos confirmar esse valor no SQL:

![54e7d6f746951b173fe7d3ff982c8827.png](../_resources/54e7d6f746951b173fe7d3ff982c8827.png)

Como podemos ver, √© exatamente o mesmo valor no PowerBI, a soma do valor unit√°rio bate, e isso significa que nossa rela√ß√£o foi feita corretamente.

## Ajustes de tipos de dados (para otimiza√ß√£o do PBI)

No PBI campos com o tipo n√∫mero s√£o otimizados para facilitar a cria√ß√£o de medidas, calculos, etc. Por√©m alguns campos (em nosso caso as chaves artificiais) tamb√©m s√£o desse mesmo tipo e isso consome processamento mesmo que n√≥s n√£o fa√ßamos calculos ou medidas com esses campos, o PBI processa eles como n√∫meros e deixa ali eles preparados para os c√°lculos, por isso devemos mudar a tipagem deles. Mudaremos eles para varchar (texto). Isso √© feito principalmente para chaves artificiais, IDs e c√≥digos ou qualquer n√∫mero que saibamos que n√£o iremos realizar nenhum calculo (ex: CPF, RG, N¬∫ de Matr√≠cula).

## Cria√ß√£o e relacionamento de Dimens√£o Data

A dimens√£o de calend√°rio √© crucial por v√°rias raz√µes, todas relacionadas √† necessidade de analisar dados ao longo do tempo. √â essencial para transformar dados em informa√ß√µes valiosas e acion√°veis, proporcionando a base necess√°ria para uma an√°lise temporal robusta e consistente em ambientes de BI.

Para isso precisamos fazer uma nova tabela com dados de data baseados em outras tabelas, precisamos que as datas se iniciem no dia primeiro do mes 01 e se encerrem no dia 31 do mes 12.

Poderiamos pegar os dados de venda, por√©m n√£o necessariamente a primeira venda do ano foi feita no primeiro dia do ano e nem a ultima venda do ano no ultimo dia do ano, ent√£o para isso usei os dados do campo "data emiss√£o" da tabela fato venda, logo peguei o StartMonth e FirstDate do campo Data Emiss√£o.

Para o EndDate usei a data de or√ßamento, pois o or√ßamento √© projetado at√© o final do ano. Logo usei o EndOfMonth e LastDate no campo Data_Ref da tabela Fato_Meta. Tudo isso dentro de uma fun√ß√£o calendar do DAX:

"<span style="color: #3165bb;">CALENDAR</span><span style="color: #000000;">(</span><span style="color: #3165bb;">STARTOFMONTH</span><span style="color: #000000;">(</span><span style="color: #3165bb;">FIRSTDATE</span><span style="color: #000000;">(</span><span style="color: #001080;">FATO_VENDA</span><span style="color: #001080;">\[DATA_EMISSAO\]</span><span style="color: #000000;">)),</span> <span style="color: #3165bb;">ENDOFMONTH</span><span style="color: #000000;">(</span><span style="color: #3165bb;">LASTDATE</span><span style="color: #000000;">(</span><span style="color: #001080;">FATO_META</span><span style="color: #001080;">\[DATA_REF\]</span><span style="color: #000000;">)))</span>¬†"

Isso at√© poderia funcionar para outras ocasi√µes, mas n√£o para mim. Ent√£o usei variaveis. Criamos uma variavel chamada DIA_INI e for√ßamos que ela receba o valor "01", farei outra variavel chamada MES_INI que recebe a express√£o MONTH que recebe a express√£o FIRSTDATE do campo Data Emiss√£o da tabela Fato Vendas, ou seja, eu pego apenas o m√™s da primeira data do campo Data Emiss√£o da tabela Fato Venda. Fa√ßo a mesma coisa por√©m para a vari√°vel ano, substituo o MONTH por YEAR e temos o ano inicial.  
<br/>Para as datas finais √© o mesmo processo, por√©m inv√©s de "01" em DIA_INI ser√° "31" e o nome da variavel muda para DIA_FIM, onde for FIRSTDATE ser√° LASTDATE e inv√©s de pegarmos o campo Data Emiss√£o da Fato Venda, pegaremos o campo Data Ref da Fato Meta.

Agora podemos usar um RETURN e usar o Calendar, dentro do Calendar usaremos a fun√ß√£o DATE para montar essa data. O primeiro DATE leva as variaveis "ANO_INI", "MES_INI" e "DIA_INI", j√° o segundo DATE leva as variaveis "ANO_FIM", "MES_FIM" e "DIA_FIM". Assim, temos montada nossa dimens√£o de calend√°rio:  
![9e58b6bcb062006ee3aa94933c93bd1a.png](../_resources/9e58b6bcb062006ee3aa94933c93bd1a.png)

N√£o podemos nos esquecer de marcar essa tabela como tabela de data e definir a coluna acima como coluna de data.

Agora iremos criar novas colunas baseadas na coluna DATA_REF (coluna inicial que criamos com as datas) para nos ajudar na cria√ß√£o do dashboard, a primeira coluna ser√° a MES que conter√° o mes em formato num√©rico, a segunda coluna ser√° o ANO que conter√° o ano da data incial, a terceira coluna ser√° MESNOME que conter√° o mes em formato de texto (nome do mes) com apenas 3 caracteres para nos ajudar em quest√£o de espa√ßo, a pr√≥xima coluna √© a TRIMESTRE a qual usei o format com a data e o "q" de quarter concatenado com um "T" para simbolizar o trimestre, a pr√≥xima coluna ser√° a MES/ANO a qual tem o m√™s em formato num√©rio e o ano. E assim temos nossa dimens√£o de calend√°rio:|  
![dbfa62ccdd8de91b7c48079dd937cda5.png](../_resources/dbfa62ccdd8de91b7c48079dd937cda5.png)

Agora, em nosso modelo temos que fazer a rela√ß√£o dela, pois est√° flutuando, faremos a rela√ß√£o dela pelo campo DATA_REF com a tabela FATO_VENDA no campo DATA_EMISSAO e tamb√©m ligaremos nossa dimens√£o de calend√°rio com a nossa FATO_META usando o campo DATA_REF o qual existe em ambas as tabelas, ficando assim o nosso modelo final:  
![2ae4a1eee77614d54affdedd5cc2c681.png](../_resources/2ae4a1eee77614d54affdedd5cc2c681.png)

## Cria√ß√£o da Tabela de Medidas

√â aqui onde criamos todas as KPIs que precisamos. Para isso criamos uma nova tabela chamada \_Medidas e nela criamos nossos KPIs, por exemplo:  
![d6adfb77792d62a7d69636dcbe67824d.png](../_resources/d6adfb77792d62a7d69636dcbe67824d.png)  
Acima nos temos algumas KPIs simples, Total Faturado que √© a soma de Quantidade de Vendas \* Valor Unit√°rio (usamos SUMX para isso, o qual soma o resultado de uma express√£o), temos o Total Meta que √© simplesmente a soma do valor da meta, e temos a Porcentagem Realizada, a qual nos informa quantos % da meta foi realizada por cada vendedor ou gerente, depende de como queremos visualizar, para isso dividimos o Total Faturado pelo Total Meta, e temos isso:  
![51591b434bef2a6f07947b1b75775823.png](../_resources/51591b434bef2a6f07947b1b75775823.png)  
Temos o nome fantasia da empresa (matriz ou filial), temos o nome dos Gerentes de cada empresa (filial ou Matriz), temos os nomes dos vendedores alocados a cada gerente, temos o total faturado, total da meta e a % Realizado, **com isso nos temos o Drill-Down das informa√ß√µes de venda, temos uma granularidade, um n√≠vel de detalhamento, n√≥s sabemos que o vendedor Malcon Dexter o qual o superior respons√°vel √© o Tiago Fielder da empresa Matriz teve um Total Faturado de 1.019.560,33 reais, a meta dele era 1.2244.273,95 e sabemos que ele ainda n√£o bateu a meta dele e est√° em 88% da mesma.** E ainda poderiamos fazer com menos granularidade, apenas com dados de gerentes.

&nbsp;

![044eeb79be359a5b586039bc39e95fc4.png](../_resources/044eeb79be359a5b586039bc39e95fc4.png)

Agora n√≥s temos mais informa√ß√µes, como o custo da venda, Lucro e % de Lucro, o Custo da venda foi feito somando os resultados da multiplica√ß√£o entre quantidade de venda e valor custo. O Lucro √© simplesmente a subtra√ß√£o de total faturado e custo de venda. A % de Lucro √© a divis√£o de total faturado e custo de venda - 1.

### Medidas R√°pidas

Podemos usar as medidas r√°pidas as quais trazem varias medidas padr√µes j√° prontas para n√≥s. E n√≥s temos as de inteligencia de dados temporais, n√≥s usaremos elas agora. Faremos primeiro o Month Over Month (MOM) que aqui seria a op√ß√£o Altera√ß√£o de m√™s a m√™s. Ou podemos fazer tamb√©m o Year Over Year:  
![11301cee2416af539c463b05ffd19bdc.png](../_resources/11301cee2416af539c463b05ffd19bdc.png)  
Usar medidas r√°pidas para mexer com data √© bem melhor que fazer na m√£o.

**R√°pidas anota√ß√µes:**

> ****YOY** significa "Year Over Year" e refere-se √† compara√ß√£o de um valor em um determinado per√≠odo com o mesmo per√≠odo no ano anterior. Esta m√©trica √© √∫til para avaliar tend√™ncias de longo prazo e eliminar varia√ß√µes sazonais.**
> 
> ****MOM** significa "Month Over Month" e refere-se √† compara√ß√£o de um valor em um determinado m√™s com o valor do m√™s anterior. Esta m√©trica √© √∫til para identificar mudan√ßas de curto prazo e responder rapidamente a flutua√ß√µes recentes.**
> 
> - **YOY**: Usado para identificar tend√™ncias anuais e analisar o crescimento ou decl√≠nio de m√©tricas-chave ao longo dos anos. Ajuda a entender o desempenho do neg√≥cio em um contexto sazonal ou anual.
> - **MOM**: Usado para monitorar o desempenho mensal e responder rapidamente a mudan√ßas recentes. Ajuda a identificar padr√µes de curto prazo e tomar decis√µes r√°pidas baseadas em dados mensais.

&nbsp;

Agora vamos fazer YOY e MOM mas com rela√ß√£o ao Valor (antes fizemos em rela√ß√£o ao faturamento). Aqui farei na m√£o inv√©s de usar as medidas r√°pidas para fins de aprendizado. O MoM de Valor √© feito assim: **MoM $ = CALCULATE(SUMX(FATO_VENDA, FATO_VENDA\[QTD\]\*FATO_VENDA\[VAL_UNIT\]), PREVIOUSMONTH(D_CALENDAR\[DATA_REF\]))**

Para YoY s√≥ muda o nome e o que inv√©s de usarmos previousmonth usamos sameperiodlastyear. Vamos analisar um exemplo:  
![27a651ee8a79cd90e4b621b5fa229b7f.png](../_resources/27a651ee8a79cd90e4b621b5fa229b7f.png)

Podemos ver por exemplo, que o m√™s 02 de 2017 em rela√ß√£o ao m√™s 01 obteve uma queda de 39% no total de faturamento. Por√©m no m√™s 03 comparado ao 02 tivemos um aumento de 59%. Ao final do ano de 2017 podemos fazer a analise de YoY:  
![12c45eed7ec0b764f51358a424eca15f.png](../_resources/12c45eed7ec0b764f51358a424eca15f.png)  
Aqui vemos que o m√™s 01 de 2018 comparado ao mesmo m√™s do ano de 2017 teve um aumento de 38% no faturamento.

### Medidas de Apoio em Filtro

Essas medidas s√£o c√°lculos ou express√µes que n√£o s√£o necessariamente mostrados diretamente em relat√≥rios ou dashboards, mas que suportam ou facilitam a cria√ß√£o de outras medidas mais complexas, visualiza√ß√µes e an√°lises.

Por exemplo, podemos ter a data da √∫ltima venda (ou ultimo m√™s de venda), ent√£o fazer essa express√£o: Ultimo Mes de Venda = CALCULATE(MAX(FATO_VENDA\[DATA_EMISSAO\]), ALL(FATO_VENDA))

Acima pegamos o valor Maximo do campo data emiss√£o e for√ßamos que ele seja o √∫ltimo independente do contexto (n√£o sofre filtragem).¬† E ainda podemos usar um Format para termos apenas o M√™s e Ano: Ultimo Mes de Venda = FORMAT(CALCULATE(MAX(FATO_VENDA\[DATA_EMISSAO\]), ALL(FATO_VENDA)), "MM/YYYY").

N√≥s usamos essas medidas para fazer coluna com condi√ß√µes em nossa dimens√£o calend√°rio, ent√£o fazemos: Ultimo Mes = IF(\[Ultimo Mes de Venda\]=D_CALENDAR\[MES/ANO\], "S", "N"), isso n√≥s retorna uma coluna que s√≥ √© preenchida com "S" quando a data √© 10/2019, a √∫ltima data de venda. Isso nos vai ajudar a fazer um filtro para trazer sempre o √∫ltimo m√™s vigente. Fizemos isso pro mes, agora farei para o ano. E aqui temos as colunas auxiliares:  
![bce778990e95533400d374679746139b.png](../_resources/bce778990e95533400d374679746139b.png)

Elas nos ajudar√£o a fazer filtros para vermos o ano inteiro atual ou o m√™s atual.

### Fun√ß√µes para interpreta√ß√£o

Aqui faremos fun√ß√µes que nos ajudam a interpretar os dados de forma mais intuitiva, sabendo se algo esta crescendo ou caindo, por meio de setas, emojis, imagens etc. No primeiro exemplo n√≥s usaremos o SWITCH inv√©s do IF pois teremos mais de 2 op√ß√µes. Iremos fazer para o MoM. Fiz a seguinte fun√ß√£o:  
KPI MoM = SWITCH(TRUE(), \[Total Fat\] = \[MoM $\], "‚èµ", \[Total Fat\] &lt; \[MoM $\], "‚è∑", \[Total Fat\] &gt;= \[MoM $\], "‚è∂", "0")  
<br/>Usando o SWITCH fiz uma fun√ß√£o que verifica se o total faturado √© maior que o MoM, igual ou Menor e atribu√≠ simbolos a isso. Fiz para YoY tamb√©m e esse foi o resultado:¬†  
![0ea2bd932307a5d73c223f4c137e32ce.png](../_resources/0ea2bd932307a5d73c223f4c137e32ce.png)

Al√©m desses KPIs informativos tamb√©m fiz mais dois bem parecidos, o primeiro √© o KPI Meta o qual verifica se a meta foi batida ou n√£o: KPI Meta = SWITCH( TRUE(), \[%Realiz\] &lt; 1, "üü†", \[%Realiz\] &gt;= 1, "üü¢", "0" ), aqui usamos o 1 pois ele equivale a 100%.

E tamb√©m fiz o KPI Lucro: KPI Lucro = SWITCH( TRUE(), \[Lucro\] = 0, "üü°", \[Lucro\] &lt; 0, "üü†", \[Lucro\] &gt; 0, "üü¢", "0" ) ele verifica se o lucro √© = a 0, menor que 0 ou maior. Veja:  
![c7a830595d8f3ee10d2aff61496e0131.png](../_resources/c7a830595d8f3ee10d2aff61496e0131.png)  
Note que apenas 1 vendedor bateu a meta, o Charles Noix com 160%, em lucro todos lucraram mesmo que pouco.

As pr√≥ximas medidas de interpreta√ß√£o foram a jun√ß√£o de duas em uma:  
![654036e062b0d67588b0b110c2289625.png](../_resources/654036e062b0d67588b0b110c2289625.png)  
O MoM √© a jun√ß√£o do KPI MoM % e o KPI de interpreta√ß√£o que usa emojis: MoM = IF(ISBLANK(\[MoM%\]), " ", VALUE(ROUND(\[MoM%\]\*100, 2))& "%" & " " &\[KPI MoM\]) para o YoY √© a mesma coisa por√©m usando o YoY.

### Medidas de Apoio ao gr√°fico Gauge

Precisamos de duas medidas de apoio para o gr√°fico gauge, sendo elas a Meta Zero a qual recebe o valor 0, e o Meta 120 o qual recebe o valor de total da meta \* 1.2, isso garante que quando o gr√°fico bater a meta ele n√£o acabe, tendo uma "gordurinha" de 20%. Ou seja, nosso gr√°fico de gauge n√£o acabar√° na meta.

# Cria√ß√£o do Dashboard

N√≥s podemos fazer filtros na p√°gina inteira, assim todos os elementos pegam esse filtro. Meu primeiro dashboard ser√° um Painel Mensal o qual exibe dados do m√™s atual (definido em uma medida de apoio na tabela dimens√£o calend√°rio), logo usaremos como filtro o campo M√™s Atual criado na dimens√£o calend√°rio.